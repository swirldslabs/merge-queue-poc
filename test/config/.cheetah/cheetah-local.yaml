log:
  fileLogging: true
  level: Info
  directory: test/logs
  fileName: cheetah.log
  maxSize: 100 # in MB
  maxBackups: 10
  maxAge: 30
profiling:
  enabled: true
  interval: 5s
  directory: test/stats
  enableServer: true
  serverHost: 127.0.0.1
  serverPort: 6060
  maxSize: 100 # in MB
#metrics: # TODO
#    enabled: true
#    interval: 5s
pipelines:
  - name: record-stream-uploader
    stopOnError: true
    scanner:
      directory: /tmp/solo-cheetah/data/hgcapp/recordStreams #/tmp/solo-cheetah/data/hgcapp/recordStreams
      pattern: ".rcd_sig"
      interval: 100ms
      batchSize: 1000
    processor: # each processor can upload to multiple storages concurrently or sequentially
      maxProcessors: 20
      fileExtensions: [ ".rcd", ".rcd_sig" ]
      retry:
        limit: 5
      storage:
        s3:
          enabled: true
          bucket: cheetah
          region: us-east-1
          prefix: streams/record-streams
          endpoint: localhost:9000
          accessKey: S3_ACCESS_KEY # use this env variable
          secretKey: S3_SECRET_KEY # use this env variable
          useSsl: false
        gcs:
          enabled: false
          bucket: lenin-test
          region: us-east-1
          prefix: cheetah/streams/record-streams
          endpoint: storage.googleapis.com
          accessKey: GCS_ACCESS_KEY # use this env variable
          secretKey: GCS_SECRET_KEY # use this env variable
          useSsl: true
        localDir: # not needed, it is used for dev/testing
          enabled: true
          path: /tmp/solo-cheetah/data/backup/recordStreams
          mode: 0755
  - name: events-stream-uploader
    stopOnError: true
    scanner:
      directory: test/data/hgcapp/eventsStreams
      pattern: ".evts_sig"
      interval: 100ms
    processor: # each processor can upload to multiple storages concurrently or sequentially
      maxProcessors: 10
      fileExtensions: [ ".evts", ".evts_sig" ]
      retry:
        limit: 5
      storage:
        s3:
          enabled: false
          bucket: cheetah
          region: us-east-1
          prefix: streams/events-streams
          endpoint: localhost:9000
          accessKey: S3_ACCESS_KEY # use this env variable
          secretKey: S3_SECRET_KEY # use this env variable
          useSsl: false
        gcs:
          enabled: false
          bucket: lenin-test
          region: us-east-1
          prefix: cheetah/streams/events-streams
          endpoint: storage.googleapis.com
          accessKey: GCS_ACCESS_KEY # use this env variable
          secretKey: GCS_SECRET_KEY # use this env variable
          useSsl: true
        localDir: # not needed, it is used for dev/testing
          enabled: true
          path: test/data/backup/eventsStreams
          mode: 0755
  - name: block-stream-uploader
    stopOnError: true
    scanner:
      directory: /tmp/solo-cheetah/data/hgcapp/blockstreams
      pattern: ".mf"
      interval: 100ms
      batchSize: 1000
    processor: # each processor can upload to multiple storages concurrently or sequentially
      maxProcessors: 20
      fileExtensions: [ ".blk.gz" ]
      retry:
        limit: 5
      storage:
        s3:
          enabled: true
          bucket: cheetah
          region: us-east-1
          prefix: streams/block-streams
          endpoint: localhost:9000
          accessKey: S3_ACCESS_KEY # use this env variable
          secretKey: S3_SECRET_KEY # use this env variable
          useSsl: false
        gcs:
          enabled: false
          bucket: lenin-test
          region: us-east-1
          prefix: cheetah/streams/block-streams
          endpoint: storage.googleapis.com
          accessKey: GCS_ACCESS_KEY # use this env variable
          secretKey: GCS_SECRET_KEY # use this env variable
          useSsl: true
        localDir: # not needed, it is used for dev/testing
          enabled: false
          path: /tmp/solo-cheetah/data/backup/block-streams
          mode: 0755
